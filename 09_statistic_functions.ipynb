{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1145cd-d9e2-4a1b-9544-e45d2a683c3e",
   "metadata": {},
   "source": [
    "# NumPy Statistical Functions \n",
    "\n",
    "NumPy provides a wide range of statistical functions to analyze data in arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc20deb-23b6-456c-a75f-57d1b2c5f8ba",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d7a8d-1f26-4d3c-bd11-24ee6c6614c3",
   "metadata": {},
   "source": [
    "In NumPy, mean is a function that calculates the arithmetic mean (average) of the elements in an array or along a specified axis. It is a commonly used statistical operation for analyzing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f15b67-6870-4db6-8958-aad4e1242a4f",
   "metadata": {},
   "source": [
    "### Syntax\n",
    "```\n",
    "numpy.mean(arr, axis=None, dtype=None, keepdims=False)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b39c7ac9-47fb-4a70-b8e6-8883ba38e57e",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- `arr`: Input array (can be any array-like object).\n",
    "- `axis` (optional): Axis or axes along which the mean is computed. If None, the mean of the flattened array is returned.\n",
    "- `axis=0`: Mean along columns (for 2D arrays).\n",
    "- `axis=1`: Mean along rows (for 2D arrays).\n",
    "- `dtype` (optional): Data type for computing the mean (e.g., float64).\n",
    "- `keepdims` (optional): If True, retains reduced dimensions as size 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9bd82-c74a-4711-8c95-3f8686dbaecb",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a199228-b8c4-4664-85db-22878f3a28c5",
   "metadata": {},
   "source": [
    "#### Mean of a 1D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad8ca5-7f3f-4dc8-92f5-ca7667ada311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "mean_val = np.mean(arr)\n",
    "print(mean_val)  # Output: 3.0 (since (1+2+3+4+5)/5 = 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1adfb-d306-4b30-98af-205323af0835",
   "metadata": {},
   "source": [
    "#### Mean of a 2D Array (Along Rows or Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c82de-8891-42ac-aa40-31cff40ef93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Overall mean\n",
    "print(np.mean(arr_2d))  # Output: 3.5\n",
    "\n",
    "# Mean along columns (axis=0)\n",
    "print(np.mean(arr_2d, axis=0))  # Output: [2.5 3.5 4.5]\n",
    "\n",
    "# Mean along rows (axis=1)\n",
    "print(np.mean(arr_2d, axis=1))  # Output: [2. 5.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da62200-0780-41d2-9299-ee8213d2139c",
   "metadata": {},
   "source": [
    "#### Specifying Data Type (dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681f065-ac6c-4729-a07b-0866c6976f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "mean_float = np.mean(arr, dtype=np.float64)\n",
    "print(mean_float)  # Output: 2.5 (instead of integer division)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f56d05-2974-451e-8da5-d6e01399c0e8",
   "metadata": {},
   "source": [
    "#### Keeping Dimensions (keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7416cfc-aac7-42c1-947e-15ed06fad96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1, 2], [3, 4]])\n",
    "mean_axis0 = np.mean(arr, axis=0, keepdims=True)\n",
    "print(mean_axis0)  # Output: [[2. 3.]] (shape (1, 2) instead of (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203693df-a9d9-43b8-831b-d944766bc53a",
   "metadata": {},
   "source": [
    "## Median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a869a-3e2a-4a5d-94b8-efe0a1bfadaf",
   "metadata": {},
   "source": [
    "In NumPy, the median is a statistical measure that represents the middle value of a dataset when it is sorted in ascending or descending order. If the dataset has an odd number of elements, the median is the middle value. If the dataset has an even number of elements, the median is the average of the two middle numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d9d42-9d91-4460-9cc0-d2d22a12851f",
   "metadata": {},
   "source": [
    "### Syntax:\n",
    "```\n",
    "numpy.median(a, axis=None, keepdims=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e41fc3-98b0-4699-90cd-96899aab89ba",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- `a`: Input array or object that can be converted to an array.\n",
    "- `axis` (optional): Axis or axes along which the median is computed (default is None, which computes the median of the flattened array).\n",
    "- `keepdims` (optional): If True, the reduced axes are kept as dimensions with size 1 (default is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c94ff-d54b-40f0-975e-a9f0940c5d46",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb737fb-fe6e-4b65-899e-d66a6900616c",
   "metadata": {},
   "source": [
    "#### Median of a 1D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21622301-0c99-4cd9-a907-082d4d4d78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([3, 1, 5, 2, 4])\n",
    "med = np.median(arr)\n",
    "print(med)  # Output: 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae69f3c-a319-454a-9a0c-52710a7fac85",
   "metadata": {},
   "source": [
    "#### Median of a 2D Array (Along an Axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a69aa-7894-42db-82b5-48a5059f0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Median of the entire array\n",
    "print(np.median(arr_2d))  # Output: 5.0\n",
    "\n",
    "# Median along axis 0 (columns)\n",
    "print(np.median(arr_2d, axis=0))  # Output: [4. 5. 6.]\n",
    "\n",
    "# Median along axis 1 (rows)\n",
    "print(np.median(arr_2d, axis=1))  # Output: [2. 5. 8.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701abc6-e592-4231-a01d-4a9851658517",
   "metadata": {},
   "source": [
    "#### Median with Even Number of Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c4d6f-5f77-4e66-9838-c6cbfec4b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_even = np.array([1, 3, 5, 7])\n",
    "med_even = np.median(arr_even)\n",
    "print(med_even)  # Output: 4.0 (average of 3 and 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975db093-4e09-4741-94b0-2d153d697738",
   "metadata": {},
   "source": [
    "### Key Notes:\n",
    "- If the input array contains NaN (Not a Number), you can use `numpy.nanmedian()` to ignore `NaN` values.\n",
    "- The median is a robust measure of central tendency and is less affected by outliers compared to the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ba5c0-6b9d-4015-b917-7a0713714c8c",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b10291-ab7e-452e-9066-dca5f9c256ac",
   "metadata": {},
   "source": [
    "- Measures how far each number in a dataset is from the mean (spread).\n",
    "- Formula (for a population): <br />\n",
    "  ![variance_population](./images/variance_population.png \"variance population\")\n",
    "- Formula (for a sample): <br />\n",
    "  ![variance_sample](./images/variance_sample.png \"variance sample\")\n",
    "- Example: For 1,2,3, the mean is 2, and the variance is <br />\n",
    "  ![variance](./images/variance.png \"variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198c743-cd03-48bd-a332-92050b409664",
   "metadata": {},
   "source": [
    "In NumPy, variance is a measure of how spread out the values in an array are. It quantifies the dispersion of data points around the mean (average) value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493ca60-682c-459f-8fdf-49438767fa2b",
   "metadata": {},
   "source": [
    "### Types of Variance in NumPy\n",
    "1. np.var() (Sample Variance by default):\n",
    "    - Computes the variance of an array.\n",
    "    - By default, it calculates the population variance (divides by n where n is the number of elements).\n",
    "    - If ddof=1 (Delta Degrees of Freedom), it computes the sample variance (divides by n - 1).\n",
    "\n",
    "2. np.nanvar():\n",
    "    - Computes variance while ignoring NaN (Not a Number) values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc30fa-e561-40f8-95e8-ebfd13a191de",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8f5ba-96f4-45f1-b5f5-ba653b38c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Population Variance (default)\n",
    "var_pop = np.var(data)  # divides by n\n",
    "print(var_pop)  # Output: 2.0\n",
    "\n",
    "# Sample Variance (ddof=1)\n",
    "var_sample = np.var(data, ddof=1)  # divides by n-1\n",
    "print(var_sample)  # Output: 2.5\n",
    "\n",
    "# Variance along an axis (for 2D arrays)\n",
    "data_2d = np.array([[1, 2], [3, 4]])\n",
    "var_axis0 = np.var(data_2d, axis=0)  # Variance along columns\n",
    "print(var_axis0)  # Output: [1. 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2a426-71af-441a-88ba-f1301306f286",
   "metadata": {},
   "source": [
    "## Standard Deviation (SD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2ef29-16c5-4c44-8405-f7eff770b045",
   "metadata": {},
   "source": [
    "- The square root of variance, giving a measure of spread in the same units as the data.\n",
    "- Formula: <br />\n",
    "  ![sd](./images/sd.png \"sd\")\n",
    "- Example: If variance is 4, then SD = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2464b-b575-43ea-a5a2-92550379b117",
   "metadata": {},
   "source": [
    "In NumPy, standard deviation is a measure of how spread out numbers are in an array or dataset. It quantifies the amount of variation or dispersion from the average (mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d476e1-59ee-411e-adf8-b46e2c8664c9",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e7641-cef0-4e25-b192-38232c1fc649",
   "metadata": {},
   "source": [
    "#### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fbfd8-473c-451d-bd21-d4a1698a2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 2, 3, 4, 5])\n",
    "std_dev = np.std(data)\n",
    "print(std_dev)  # Output: 1.4142135623730951"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84a1b6-78b3-4c57-aada-61ffbbb448fa",
   "metadata": {},
   "source": [
    "#### ddof (Delta Degrees of Freedom)\n",
    "- Default is 0 (population standard deviation)\n",
    "- Set to 1 for sample standard deviation (Bessel's correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01096e06-d7f1-42ce-9249-de65ee3bc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Population standard deviation (default)\n",
    "pop_std = np.std(data)  # ddof=0\n",
    "print(pop_std)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std = np.std(data, ddof=1)\n",
    "print(sample_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8afca362-c3f3-45e3-b50d-89abf79a0ae9",
   "metadata": {},
   "source": [
    "#### axis\n",
    "- Calculate along rows or columns for multi-dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc671f91-9e84-4851-aa13-e1d8ff8357eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Standard deviation of each column\n",
    "col_std = np.std(arr_2d, axis=0)\n",
    "\n",
    "# Standard deviation of each row\n",
    "row_std = np.std(arr_2d, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec49106-b058-4e75-bff7-32abbe402676",
   "metadata": {},
   "source": [
    "## Minimun & Maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95139737-e11b-4e8d-8a85-ab8d97a63bc8",
   "metadata": {},
   "source": [
    "Minimum (Min)\n",
    "- The smallest value in a dataset.\n",
    "- Example: For 5,2,8, the minimum is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8156abf-5efa-4eb8-9dd4-fb575fd80e9d",
   "metadata": {},
   "source": [
    "Maximum (Max)\n",
    "- The largest value in a dataset.\n",
    "- Example: For 5,2,8, the maximum is 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f0772-22ed-4f93-b16b-d073cd702179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Minimum & Maximum\n",
    "min_val = np.min(arr)  # 1\n",
    "max_val = np.max(arr)  # 5\n",
    "print(min_val)\n",
    "print(max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c19297-0d51-48f7-abe9-793e580320a2",
   "metadata": {},
   "source": [
    "## Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13df573-8225-40f6-9150-2e31cb49067f",
   "metadata": {},
   "source": [
    "- The result of multiplying all values in a dataset.\n",
    "- Formula: <br />\n",
    "  ![product](./images/product.png \"product\")\n",
    "- Example: For 2,3,4, the product is 2×3×4=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5903d0-2b6e-444b-87fa-0364fc013a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Product of elements\n",
    "product = np.prod(arr)  # 120\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eba767-5450-403b-b6d8-f1d612b21b39",
   "metadata": {},
   "source": [
    "## Percentiles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4f7de-65f0-445e-a071-12dd24d6151d",
   "metadata": {},
   "source": [
    "in NumPy, percentiles are used to calculate the value below which a given percentage of observations in a dataset fall. The numpy.percentile() function computes the specified percentile(s) of the data along a given axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f3fc9-3dee-4cfa-9057-de1b802291b7",
   "metadata": {},
   "source": [
    "### Syntax\n",
    "```\n",
    "numpy.percentile(a, q, axis=None, method='linear')\n",
    "```\n",
    "\n",
    "- `a`: Input array or object that can be converted to an array.\n",
    "- `q`: Percentile(s) to compute (between 0 and 100).\n",
    "- `axis`: Axis along which to compute the percentile (None for flattened array).\n",
    "- `method` (optional): Interpolation method ('linear', 'lower', 'higher', 'midpoint', 'nearest')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b50489-8c22-4ea3-bb97-03908ac1faae",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3e15e-fe90-49d0-8425-52cda3e28f0d",
   "metadata": {},
   "source": [
    "#### Basic Percentile Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905ec93-ac4f-43cb-8def-265300580dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Compute the 50th percentile (median)\n",
    "p50 = np.percentile(data, 50)\n",
    "print(p50)  # Output: 30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf5b15-4dc2-4d9a-825a-5986a5b48214",
   "metadata": {},
   "source": [
    "#### Multiple Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32e8e7-8415-44ed-aee6-a0b55911f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "percentiles = np.percentile(data, [25, 50, 75])\n",
    "print(percentiles)  # Output: [22.5 30. 37.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03517971-6701-4bed-b9c7-c69db54278e8",
   "metadata": {},
   "source": [
    "#### Along a Specific Axis (for 2D arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0833cb7-240d-4d79-8551-c2d2fff8878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Compute 50th percentile along axis=0 (columns)\n",
    "p50_axis0 = np.percentile(arr, 50, axis=0)\n",
    "print(p50_axis0)  # Output: [2.5 3.5 4.5]\n",
    "\n",
    "# Compute 50th percentile along axis=1 (rows)\n",
    "p50_axis1 = np.percentile(arr, 50, axis=1)\n",
    "print(p50_axis1)  # Output: [2. 5.]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7c1e9a9-0a08-4417-a801-20eec5f005bc",
   "metadata": {},
   "source": [
    "#### Different Interpolation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05713cb2-81b9-46c4-b6ea-4e68da797837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Different methods for interpolation\n",
    "print(np.percentile(data, 50, method='linear'))  # 3.0 (default)\n",
    "print(np.percentile(data, 50, method='lower'))   # 3 (closest lower value)\n",
    "print(np.percentile(data, 50, method='higher'))  # 3 (closest higher value)\n",
    "print(np.percentile(data, 50, method='midpoint')) # 3.0 (average of lower & higher)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c92af-2abe-4095-bf74-4f0f102bdab2",
   "metadata": {},
   "source": [
    "#### Key Notes:\n",
    "- `q` can be a single value or a list of percentiles (e.g., `[25, 50, 75]` for quartiles).\n",
    "- Interpolation matters when the desired percentile lies between two data points.\n",
    "- For large datasets, consider using `numpy.nanpercentile()` to ignore `NaN` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edeece9-4358-4aca-b508-fdfb172e2a05",
   "metadata": {},
   "source": [
    "## Quantiles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e156911-0c00-4da0-abbd-3623d32bedfa",
   "metadata": {},
   "source": [
    "In NumPy, quantiles are values that divide a dataset into equal-sized intervals. They are useful for understanding the distribution of data, identifying outliers, and summarizing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a7ed7-abec-4c98-a30c-35e9b740f7d9",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "\n",
    "1. Definition:\n",
    "    - The q-th quantile is the value below which q×100% of the data falls.\n",
    "    - For example:\n",
    "        - The 0.5 quantile (median) splits the data into two equal parts.\n",
    "        - The 0.25 quantile (1st quartile) marks the 25th percentile.\n",
    "\n",
    "2. NumPy Function:\n",
    "    - numpy.quantile(arr, q) computes the specified quantile(s) of an array.\n",
    "    - q can be a single value (e.g., 0.5) or a list of quantiles (e.g., [0.25, 0.5, 0.75]).\n",
    "\n",
    "3. Parameters:\n",
    "    - `arr`: Input array (or array-like data).\n",
    "    - `q`: Quantile value(s) between 0 and 1.\n",
    "    - `axis`: Axis along which to compute (default is None, meaning flattened array).\n",
    "    - `method`: Interpolation method (e.g., 'linear', 'lower', 'higher', 'midpoint')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461dcfb9-051d-43ce-99a1-4cce70dcb800",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f121518f-b2f4-4f97-9315-f45d12ff7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Compute the median (0.5 quantile)\n",
    "median = np.quantile(data, 0.5)\n",
    "print(median)  # Output: 30.0\n",
    "\n",
    "# Compute quartiles (0.25, 0.5, 0.75)\n",
    "quartiles = np.quantile(data, [0.25, 0.5, 0.75])\n",
    "print(quartiles)  # Output: [20. 30. 40.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db35074-a3a8-4469-bf9f-07f86c8cd46a",
   "metadata": {},
   "source": [
    "### Interpolation Methods\n",
    "When the quantile falls between two data points, NumPy uses interpolation:\n",
    "- `'linear'`: Default (weighted average of neighboring points).\n",
    "- `'lower'`/`'higher'`: Nearest lower/higher value.\n",
    "- `'midpoint'`: Average of the two closest points.\n",
    "\n",
    "Equivalent Function:\n",
    "- `numpy.percentile(arr, p)` is similar but uses percentages (e.g., `p=50` for median). Example: `np.percentile(data, 50)` is the same as `np.quantile(data, 0.5)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34981225-3d3d-4b3c-9521-3e59fc4681eb",
   "metadata": {},
   "source": [
    "## Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46bd2ca-2a7e-4d58-9128-dd34a3905755",
   "metadata": {},
   "source": [
    "In NumPy, correlation refers to the statistical relationship between two arrays, measuring how they vary together. NumPy provides functions to compute different types of correlations, including"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4b45c-9ec6-4335-b207-5b40b66ddad1",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient (Linear Correlation)\n",
    "- Measures the linear relationship between two arrays.\n",
    "- Ranges from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no linear correlation.\n",
    "- Computed using numpy.corrcoef()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6ed2e-0f13-45e6-9d2f-218c228d83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Compute Pearson correlation coefficient\n",
    "corr_matrix = np.corrcoef(x, y)\n",
    "pearson_corr = corr_matrix[0, 1]  # Correlation between x and y\n",
    "\n",
    "print(pearson_corr)  # Output: -1.0 (perfect negative correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea4fcf-8bf4-4256-97c8-4efa58c56c6c",
   "metadata": {},
   "source": [
    "### Cross-Correlation\n",
    "- Measures similarity between two signals as a function of a time lag.\n",
    "- Computed using numpy.correlate() (for 1D arrays) or numpy.cross-correlate (for ND arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6905a1-9ae3-4958-b9ad-4547c731459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([0, 1, 0.5])\n",
    "\n",
    "cross_corr = np.correlate(a, b, mode='valid')\n",
    "print(cross_corr)  # Output: [3.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ec607-9ed2-4487-aada-22e6d2cdba45",
   "metadata": {},
   "source": [
    "### Auto-Correlation\n",
    "\n",
    "- Measures how a signal correlates with a delayed version of itself.\n",
    "- Can be computed using numpy.correlate(x, x, mode='full')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54060ff-d446-4003-abc5-dc7e97971070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "auto_corr = np.correlate(x, x, mode='full')\n",
    "print(auto_corr)  # Output: [3 8 14 8 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b9de5-2941-4f65-beed-acccb3f4685b",
   "metadata": {},
   "source": [
    "### Key Notes:\n",
    "- Pearson Correlation (corrcoef) is the most common for linear relationships.\n",
    "- Cross-Correlation (correlate) is useful in signal processing.\n",
    "- For statistical applications, you might also consider scipy.stats.pearsonr or pandas.DataFrame.corr() for more features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39586e7-bea5-4521-afd6-ffcc78d61497",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917216e7-d8e9-41e3-b39b-86ce84e4bdb9",
   "metadata": {},
   "source": [
    "In NumPy, covariance refers to the measure of how much two random variables change together. The numpy.cov() function is used to compute the covariance matrix for a given dataset, which summarizes the covariances between all pairs of variables (features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f131db-608e-4615-816f-3feca0195327",
   "metadata": {},
   "source": [
    "### Key Points about numpy.cov():\n",
    "1. Input:\n",
    "    - Accepts a 2D array where rows represent variables (features) and columns represent observations (samples).\n",
    "    - Can also compute covariance between two 1D arrays (vectors).\n",
    "\n",
    "2. Output:\n",
    "    - Returns a covariance matrix (a square matrix) where:\n",
    "    - Diagonal elements are variances of each variable.\n",
    "    - Off-diagonal elements are covariances between pairs of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae46d1c-3021-42c9-b9a1-68f0f659e21d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c3085-77e8-4044-8c88-80a00b590f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data: 3 variables (rows) with 5 observations (columns)\n",
    "data = np.array([\n",
    "    [1, 2, 3, 4, 5],      # Variable X\n",
    "    [5, 4, 3, 2, 1],      # Variable Y\n",
    "    [2, 2, 2, 2, 2]       # Variable Z (constant)\n",
    "])\n",
    "\n",
    "# Compute covariance matrix\n",
    "cov_matrix = np.cov(data)\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096c8f2-b216-4a14-9bfe-6892a1c23019",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de91f6-ddd9-46a3-b240-00e539e224a8",
   "metadata": {},
   "source": [
    "NumPy provides functions to compute histograms, which are graphical representations of the distribution of numerical data. A histogram divides the data into bins (intervals) and counts how many values fall into each bin. Histograms are fundamental for data analysis and visualization, often used before more advanced statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d42dc4-271b-4fc1-ace7-b9633a0bb62c",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Key parameters for numpy.histogram():\n",
    "- `a`: Input data\n",
    "- `bins`: Can be an integer (number of bins) or a sequence (bin edges)\n",
    "- `range`: The lower and upper range of the bins\n",
    "- `density`: If True, returns probability density (normalized)\n",
    "- `weights`: Array of weights for each value in a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6e365-9249-40a2-9f6a-9e066a164691",
   "metadata": {},
   "source": [
    "### numpy.histogram()\n",
    "The main function for creating histograms in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bed04e-1f1f-4b88-8fe5-65b278547bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(1000)  # Sample data\n",
    "hist, bin_edges = np.histogram(data, bins=10)\n",
    "\n",
    "print(\"Counts per bin:\", hist)\n",
    "print(\"Bin edges:\", bin_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d34010-ac9b-4d82-926e-32f17aa49e14",
   "metadata": {},
   "source": [
    "### numpy.histogram2d()\n",
    "For creating 2D histograms from two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712b897-6848-4875-9b12-35eb64e5828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(1000)\n",
    "y = np.random.randn(1000)\n",
    "hist, xedges, yedges = np.histogram2d(x, y, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92158f8-dcdc-4373-a33e-e8ae90558b29",
   "metadata": {},
   "source": [
    "### Example with Customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9e513-c333-42ad-a01a-96e575290eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.random.normal(170, 10, 250)  # Mean=170, std=10, 250 values\n",
    "\n",
    "# Custom bins and range\n",
    "hist, bins = np.histogram(data, bins=[140, 150, 160, 170, 180, 190, 200], \n",
    "                         density=True)\n",
    "\n",
    "# Plotting (requires matplotlib)\n",
    "plt.hist(data, bins=[140, 150, 160, 170, 180, 190, 200], density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148abed3-207e-479a-aa93-2f59d4813c56",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5603200-aaa5-4b93-afa0-59fb24c4c5d6",
   "metadata": {},
   "source": [
    "In NumPy, convolve is a function that performs convolution of two one-dimensional arrays (vectors). Convolution is a mathematical operation commonly used in signal processing, image processing, and deep learning (e.g., in convolutional neural networks).\n",
    "\n",
    "`numpy.convolve(v1, v2, mode='full')`\n",
    "- `v1`: First input array (1D).\n",
    "- `v2`: Second input array (1D).\n",
    "- `mode`: Specifies the size of the output:\n",
    "    - `'full'` (default): Returns the convolution at every overlapping point (output size = len(v1) + len(v2) - 1).\n",
    "    - `'same'`: Output has the same length as the first input (v1).\n",
    "    - `'valid'`: Returns only where the two arrays fully overlap (output size = max(len(v1), len(v2)) - min(len(v1), len(v2)) + 1).\n",
    "\n",
    "In simple terms, it slides one array (v2, reversed) over the other (v1) and computes the sum of products at each position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33259c7-72dd-40f6-a8c3-2bdee936960f",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e79fe20d-6b36-4312-9012-51227859a517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  1.  2.5 4.  1.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([0, 1, 0.5])\n",
    "\n",
    "# Convolution\n",
    "result = np.convolve(a, b, mode='full')\n",
    "print(result) # [0.  1.  2.5 4.  1.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9b411-88d9-4450-9a80-3ea870aca972",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- 0.0 = 1*0\n",
    "- 1.0 = 1*1 + 2*0\n",
    "- 2.5 = 1*0.5 + 2*1 + 3*0\n",
    "- 4.0 = 2*0.5 + 3*1\n",
    "- 1.5 = 3*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823633c-c9a4-4a7d-b794-49ca0bf7e81d",
   "metadata": {},
   "source": [
    "### Common Uses\n",
    "- Signal Processing (e.g., smoothing, filtering).\n",
    "- Image Processing (applying blur, edge detection).\n",
    "- Neural Networks (CNNs use 2D convolution for feature extraction).\n",
    "\n",
    "For multi-dimensional convolution, use:\n",
    "- scipy.signal.convolve2d (2D arrays)\n",
    "- scipy.ndimage.convolve (n-dimensional arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af078375-cfb2-4707-abed-692eb00d0387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
